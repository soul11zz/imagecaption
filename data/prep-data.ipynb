{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from huggingface_hub import HfApi\n",
    "import huggingface_hub as hf_hub\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "annotations_location = r\"z:/data/labels/labels.csv\"\n",
    "images_folder = r\"z:/data/images\"\n",
    "dataset_folder = r\"z:/data/dataset\"\n",
    "metada_file = \"metadata.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_hub.notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann = pd.read_csv(annotations_location, encoding=\"utf-8\")\n",
    "df_ann.drop(columns=[\"image\"], inplace=True)\n",
    "df_ann[\"File Name\"] = df_ann[\"File Name\"].apply(lambda x: x + \".jpg\")\n",
    "df_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove entries with empty captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_image_titles = df_ann[df_ann[\"image_title\"].isna()][\"File Name\"].values\n",
    "\n",
    "for im_fn in empty_image_titles:\n",
    "    if osp.exists(osp.join(images_folder, im_fn)):\n",
    "        print(f\"Removing {im_fn}\")\n",
    "        os.remove(osp.join(images_folder, im_fn))\n",
    "df_ann = df_ann[~df_ann[\"File Name\"].isin(empty_image_titles)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "all_files = glob(osp.join(images_folder, \"*.jpg\"))\n",
    "train_val_files, test_files = train_test_split(all_files, test_size=0.15, random_state=42)\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = osp.join(dataset_folder, \"train\")\n",
    "val_dir = osp.join(dataset_folder, \"validation\")\n",
    "test_dir = osp.join(dataset_folder, \"test\")\n",
    "\n",
    "train_metadata = osp.join(train_dir, metada_file)\n",
    "val_metadata = osp.join(val_dir, metada_file)\n",
    "test_metadata = osp.join(test_dir, metada_file)\n",
    "\n",
    "def copy_files(files, dest_dir, del_existing=False):\n",
    "  \n",
    "  if not osp.exists(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "  elif del_existing:\n",
    "    shutil.rmtree(dest_dir)\n",
    "    os.mkdir(dest_dir)\n",
    "    \n",
    "  for f in files:\n",
    "      shutil.copy(f, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in zip([train_files, val_files, test_files], [train_dir, val_dir, test_dir]):\n",
    "  copy_files(*files, del_existing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary for matching files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(filter_files, metadata_file, *, df = df_ann):\n",
    "  \n",
    "  filter_files = [osp.basename(f) for f in filter_files]\n",
    "  df_filtered = df[df[\"File Name\"].isin(filter_files)]\n",
    "  label_dict = df_filtered.set_index('File Name')['image_title'].to_dict()\n",
    "  metadata = []\n",
    "  \n",
    "  for fn, label in label_dict.items():\n",
    "    strg = orjson.dumps({\"file_name\": fn, \"text\": label}).decode(\"utf-8\", \"ignore\").encode(\"utf-8\")\n",
    "    metadata.append(strg)\n",
    "    \n",
    "  with open(metadata_file, \"wb\") as f:\n",
    "    f.writelines(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metadata(train_files, train_metadata)\n",
    "create_metadata(test_files, test_metadata)\n",
    "create_metadata(val_files, val_metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "repo_name = \"soul11zz/image-caption-desc-only\"\n",
    "repo_url = api.create_repo(repo_name, private=True, exist_ok=True, repo_type=\"dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_hub(repo_name, dataset_folder, split):\n",
    "  \n",
    "  dataset = load_dataset(\"imagefolder\", data_dir=dataset_folder, split=split)\n",
    "  dataset.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_folder = r\"/Users/berno/Dropbox/zakhar/data/dataset\"\n",
    "upload_to_hub(repo_name, dataset_folder, \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upload_to_hub(repo_name, dataset_folder, \"validation\")\n",
    "upload_to_hub(repo_name, dataset_folder, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78bfdcee45ab360ff98997b0fdb262d833775071286b5e4a7c2a2c9a5871b9ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
